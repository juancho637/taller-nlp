# ğŸ¬ Generador de ReseÃ±as de PelÃ­culas

Un generador automÃ¡tico de reseÃ±as cinematogrÃ¡ficas utilizando modelos Transformer entrenados con el dataset IMDb.

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **Dos modelos Transformer diferentes** con arquitecturas optimizadas
- ğŸ›ï¸ **Control de creatividad** mediante temperatura ajustable
- ğŸ“ **Longitud configurable** de las reseÃ±as generadas
- ğŸ¬ **Vocabulario cinematogrÃ¡fico real** de 6000 tokens del dataset IMDb
- ğŸ“± **Interfaz web interactiva** con Streamlit
- âš¡ **GeneraciÃ³n en tiempo real** con filtrado inteligente

## ğŸ› ï¸ TecnologÃ­as

- **TensorFlow 2.19+** - Framework de deep learning
- **Streamlit** - Interfaz web interactiva  
- **Python 3.11+** - Lenguaje de programaciÃ³n
- **Transformer Architecture** - Modelos de atenciÃ³n personalizada

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Con UV (Recomendado)
```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/taller-nlp.git
cd taller-nlp

# Instalar dependencias
uv sync

# Ejecutar aplicaciÃ³n
./run.sh
```

### OpciÃ³n 2: Con pip tradicional
```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/taller-nlp.git
cd taller-nlp

# Crear entorno virtual
python3.11 -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar aplicaciÃ³n
streamlit run src/app.py
```

## ğŸ¯ Uso

### Ejecutar la aplicaciÃ³n
```bash
./run.sh
```
La aplicaciÃ³n estarÃ¡ disponible en: http://localhost:8501

### Configuraciones disponibles:
- **Modelo**: Transformer Modelo 1 (preciso) o Modelo 2 (creativo)
- **Temperatura**: 0.1-2.0 (creatividad del texto)
- **Longitud**: 20-200 palabras

### Ejemplos de prompts:
- `"Esta pelÃ­cula de acciÃ³n"`
- `"El drama protagonizado por"`
- `"Una comedia que nos presenta"`

## ğŸ‹ï¸ Entrenamiento de Modelos

### Entrenar ambos modelos:
```bash
cd src
python train.py --modelo ambos --epocas1 40 --epocas2 25
```

### Entrenar solo Modelo 1:
```bash
python train.py --modelo 1 --epocas1 40
```

### Entrenar solo Modelo 2:
```bash
python train.py --modelo 2 --epocas2 20
```

### Opciones avanzadas:
```bash
# Limpiar modelos anteriores
python train.py --modelo 1 --limpiar

# Crear nuevo vectorizador
python train.py --modelo 1 --nuevo-vectorizador

# ConfiguraciÃ³n personalizada
python train.py --modelo ambos --epocas1 50 --epocas2 15 --limpiar
```

## ğŸ“Š Arquitectura del Proyecto

```
src/
â”œâ”€â”€ app.py                  # Interfaz Streamlit principal
â”œâ”€â”€ config.py               # Configuraciones del modelo
â”œâ”€â”€ train.py                # Script de entrenamiento
â”œâ”€â”€ models/
â”‚   â””â”€â”€ transformer_models.py  # Arquitecturas Transformer
â””â”€â”€ utils/
    â”œâ”€â”€ data_utils.py       # Utilidades de procesamiento de datos
    â””â”€â”€ text_generator.py   # LÃ³gica de generaciÃ³n de texto
```

## ğŸ§  Modelos

### Transformer Modelo 1
- **ParÃ¡metros**: ~7.8M
- **CaracterÃ­sticas**: Una capa transformer, convergencia estable
- **Uso recomendado**: Texto preciso y coherente

### Transformer Modelo 2  
- **ParÃ¡metros**: ~12.5M
- **CaracterÃ­sticas**: Dos capas transformer, mÃ¡s expresivo
- **Uso recomendado**: Texto creativo y variado

## âš™ï¸ ConfiguraciÃ³n

### ParÃ¡metros del modelo (config.py):
```python
SEQUENCE_LENGTH = 80      # Longitud de secuencia
VOCAB_SIZE = 6000         # TamaÃ±o del vocabulario
EMBED_DIM = 256          # DimensiÃ³n de embeddings
LATENT_DIM = 1024        # DimensiÃ³n latente
NUM_HEADS = 8            # Cabezas de atenciÃ³n
```

### ParÃ¡metros de entrenamiento:
```python
BATCH_SIZE = 16          # TamaÃ±o del batch
EPOCHS = 40              # Ã‰pocas mÃ¡ximas
SAMPLE_SIZE = 8000       # Muestras del dataset
LEARNING_RATE = 0.0005   # Tasa de aprendizaje
```

## ğŸ® Ejemplos de Uso

### Generar reseÃ±a de acciÃ³n:
**Input**: `"Esta pelÃ­cula de acciÃ³n"`  
**Output**: `"Esta pelÃ­cula de acciÃ³n delivers outstanding performances with brilliant cinematography and explosive sequences that keep viewers engaged throughout the entire runtime."`

### Generar reseÃ±a de drama:
**Input**: `"El drama protagonizado por"`  
**Output**: `"El drama protagonizado por talented actors explores deep emotional themes with exceptional direction and compelling storytelling that resonates with audiences."`

## ğŸ”§ SoluciÃ³n de Problemas

### Modelos no encontrados:
```bash
# Entrenar modelos desde cero
cd src
python train.py --modelo ambos --limpiar
```

### Error de memoria:
- Reducir `BATCH_SIZE` en `config.py`
- Reducir `SAMPLE_SIZE` para usar menos datos

### GeneraciÃ³n incoherente:
- Ajustar temperatura (0.5-0.7 para mÃ¡s coherencia)
- Usar Modelo 1 para mayor precisiÃ³n

## ğŸ“ˆ Rendimiento

- **Tiempo de entrenamiento**: 25-40 minutos (Mac M1 Pro)
- **Velocidad de generaciÃ³n**: ~2-3 segundos por reseÃ±a
- **PrecisiÃ³n**: Loss final ~0.04-4.5 dependiendo del modelo
- **Vocabulario**: 6000 tokens de palabras reales de cine

## ğŸ™ Reconocimientos

- Dataset IMDb para entrenamiento
- TensorFlow team por el framework
- Streamlit por la interfaz web
- Arquitectura Transformer original de "Attention Is All You Need"