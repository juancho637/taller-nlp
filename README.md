# ğŸ¬ Generador de ReseÃ±as de PelÃ­culas con Transformers

Un generador automÃ¡tico de reseÃ±as cinematogrÃ¡ficas utilizando **dos modelos Transformer** con arquitecturas diferenciadas, entrenados con el dataset IMDb.

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¤– **Dos modelos Transformer independientes** con configuraciones optimizadas
- ğŸ—ï¸ **Arquitectura modular** - cada modelo en su propio archivo
- ğŸ“Š **InformaciÃ³n dinÃ¡mica** - mÃ©tricas reales extraÃ­das del modelo cargado
- ğŸ›ï¸ **Control de creatividad** mediante temperatura ajustable
- ğŸ“ **Longitud configurable** de las reseÃ±as generadas
- ğŸ“± **Interfaz web simplificada** con Streamlit
- âš¡ **Entrenamiento por separado** con script centralizado

## ğŸ—ï¸ Estructura del Proyecto

```
src/
â”œâ”€â”€ train.py        # ğŸš€ Script central de entrenamiento
â”œâ”€â”€ model_1.py      # ğŸ¤– Modelo 1: Transformer Simple (1 capa)
â”œâ”€â”€ model_2.py      # ğŸ¤– Modelo 2: Transformer Doble (2 capas)
â””â”€â”€ app.py          # ğŸ“± Interfaz web con Streamlit
```

### ğŸ“‹ DescripciÃ³n de Archivos

| Archivo | PropÃ³sito | Contenido |
|---------|-----------|-----------|
| `train.py` | Script principal | CoordinaciÃ³n de entrenamiento, preparaciÃ³n de datos |
| `model_1.py` | Transformer Simple | ConfiguraciÃ³n y arquitectura de 1 capa |
| `model_2.py` | Transformer Doble | ConfiguraciÃ³n y arquitectura de 2 capas |
| `app.py` | Interfaz web | Carga de modelos, summary real, generaciÃ³n |

## ğŸ¤– Modelos Implementados

### ğŸ¯ Modelo 1 - Transformer Simple
- **Capas:** 1 capa Transformer
- **ParÃ¡metros:** ~7.8M 
- **Ã‰pocas:** 15
- **Learning Rate:** 0.001
- **Fortalezas:** Estable, rÃ¡pido, ideal para principiantes
- **Tiempo entrenamiento:** 10-15 minutos

### ğŸ¯ Modelo 2 - Transformer Doble  
- **Capas:** 2 capas Transformer
- **ParÃ¡metros:** ~12.5M
- **Ã‰pocas:** 20 
- **Learning Rate:** 0.0005
- **Fortalezas:** MÃ¡s expresivo, creativo, para usuarios avanzados
- **Tiempo entrenamiento:** 15-25 minutos

### ğŸ”§ ConfiguraciÃ³n Compartida
```python
VOCAB_SIZE = 5000           # Vocabulario de palabras
SEQUENCE_LENGTH = 60        # Longitud mÃ¡xima de secuencia
EMBED_DIM = 128            # DimensiÃ³n de embeddings
NUM_HEADS = 4              # Cabezas de atenciÃ³n
SAMPLE_SIZE = 2000         # Muestras de entrenamiento IMDb
```

## ğŸš€ InstalaciÃ³n y Uso

### ğŸ“¦ InstalaciÃ³n
```bash
# Clonar repositorio
git clone <tu-repositorio>
cd generador-resenas-transformer

# Instalar dependencias
pip install tensorflow streamlit numpy matplotlib
```

### ğŸ‹ï¸ Entrenamiento de Modelos

#### Comandos Principales
```bash
# Entrenar solo Modelo 1 (recomendado para empezar)
python src/train.py --model 1

# Entrenar solo Modelo 2 (mÃ¡s avanzado)
python src/train.py --model 2

# Entrenar ambos modelos secuencialmente
python src/train.py --model both
```

#### Comandos de InformaciÃ³n
```bash
# Ver configuraciÃ³n del Modelo 1
python src/train.py --info 1

# Ver configuraciÃ³n del Modelo 2
python src/train.py --info 2

# Ver estado de modelos guardados
python src/train.py --status

# Comparar ambos modelos
python src/train.py --compare
```

#### Modo Interactivo
```bash
# Sin argumentos para menÃº interactivo
python src/train.py
```

### ğŸ“± Ejecutar la AplicaciÃ³n Web
```bash
# Iniciar interfaz web (requiere modelos entrenados)
streamlit run src/app.py
```

La aplicaciÃ³n estarÃ¡ disponible en: **http://localhost:8501**

## ğŸ® Uso de la AplicaciÃ³n

### ğŸ¤– SelecciÃ³n de Modelo
- Escoge entre **Modelo 1** (simple) o **Modelo 2** (doble)
- La aplicaciÃ³n carga automÃ¡ticamente el modelo desde `saved_models/`

### ğŸ“Š Ver Detalles del Modelo
- BotÃ³n **"ğŸ“‹ Mostrar Detalles del Modelo X"**
- InformaciÃ³n extraÃ­da dinÃ¡micamente:
  - ParÃ¡metros totales y entrenables
  - Arquitectura completa con `model.summary()`
  - No hay informaciÃ³n hardcodeada

### âœï¸ GeneraciÃ³n de ReseÃ±as
1. **Escribe un prompt inicial:** "This movie is"
2. **Ajusta la creatividad:** 0.1 (conservador) - 2.0 (muy creativo)
3. **Define la longitud:** 10-100 palabras
4. **Genera:** ObtÃ©n tu reseÃ±a personalizada

### ğŸ“Š Configuraciones Recomendadas

| Modelo | Temperatura | Longitud | Mejor para |
|--------|-------------|----------|------------|
| **Modelo 1** | 0.5 - 0.8 | 30-50 palabras | Texto coherente y predecible |
| **Modelo 2** | 0.7 - 1.2 | 40-80 palabras | Contenido creativo y variado |

## ğŸ”§ Configuraciones TÃ©cnicas

### ğŸ—ï¸ Arquitectura del Modelo 1
```python
# src/model_1.py
class Model1Config:
    NUM_TRANSFORMER_LAYERS = 1      # Una capa
    DROPOUT_RATE = 0.1              # Dropout bajo
    EPOCHS = 15                     # Entrenamiento estable
    EARLY_STOPPING_PATIENCE = 5     # MÃ¡s paciencia
```

### ğŸ—ï¸ Arquitectura del Modelo 2
```python
# src/model_2.py  
class Model2Config:
    NUM_TRANSFORMER_LAYERS = 2      # Dos capas
    DROPOUT_RATE = 0.2              # MÃ¡s regularizaciÃ³n
    EPOCHS = 20                     # MÃ¡s Ã©pocas
    EARLY_STOPPING_PATIENCE = 3     # Menos paciencia (evitar overfitting)
```

## ğŸ“Š InformaciÃ³n TÃ©cnica

### ğŸ¯ Dataset
- **Fuente:** IMDb Movie Reviews
- **Muestras:** 2,000 reseÃ±as de entrenamiento
- **Vocabulario:** 5,000 palabras mÃ¡s frecuentes
- **Preprocesamiento:** TokenizaciÃ³n con TextVectorization de Keras

### ğŸ§  Arquitectura Transformer
- **Embeddings posicionales:** Suma de token + posiciÃ³n
- **Multi-Head Attention:** 4 cabezas de atenciÃ³n
- **Feed-Forward:** DimensiÃ³n latente de 256
- **Layer Normalization:** Aplicada despuÃ©s de cada bloque
- **Dropout:** RegularizaciÃ³n para evitar overfitting

### ğŸ’¾ Archivos Generados
```
saved_models/
â”œâ”€â”€ movie_model_1.keras         # Modelo 1 entrenado
â”œâ”€â”€ movie_model_2.keras         # Modelo 2 entrenado
â””â”€â”€ text_vectorizer.pkl         # Vectorizador compartido
```

## ğŸ” SoluciÃ³n de Problemas

### âŒ Error: "No se encontrÃ³ el modelo"
```bash
# Entrenar el modelo faltante
python src/train.py --model 1  # o --model 2
```

### âŒ Error: "No se encontrÃ³ text_vectorizer.pkl"
```bash
# El vectorizador se crea automÃ¡ticamente al entrenar cualquier modelo
python src/train.py --model 1
```

### ğŸŒ Entrenamiento muy lento
- Reduce `SAMPLE_SIZE` en las configuraciones
- Usa GPU si estÃ¡ disponible
- Considera entrenar solo Modelo 1 primero

### ğŸ¤– GeneraciÃ³n incoherente
- Reduce la temperatura (0.3-0.6)
- Usa Modelo 1 para mayor estabilidad
- Verifica que el modelo estÃ© bien entrenado

## ğŸ“ˆ Rendimiento Esperado

| MÃ©trica | Modelo 1 | Modelo 2 |
|---------|----------|----------|
| **ParÃ¡metros** | ~7.8M | ~12.5M |
| **Tiempo entrenamiento** | 10-15 min | 15-25 min |
| **Loss final** | ~4.5 | ~4.0 |
| **Estabilidad** | Alta | Media |
| **Creatividad** | Media | Alta |

## ğŸ¯ Ejemplos de Uso

### ğŸ“ Ejemplo 1 - Modelo 1 (Conservador)
**Input:** `"This movie is"`  
**Temperatura:** 0.6  
**Output:** `"This movie is a compelling drama that showcases excellent performances and delivers a satisfying emotional journey."`

### ğŸ“ Ejemplo 2 - Modelo 2 (Creativo)
**Input:** `"The film presents"`  
**Temperatura:** 1.0  
**Output:** `"The film presents an innovative narrative structure that challenges conventional storytelling while maintaining audience engagement through unexpected plot developments."`