"""
ğŸ¬ INTERFAZ WEB SIMPLE - UNA COLUMNA
===================================

Interfaz web sÃºper simple para generar reseÃ±as.
Ejecutar: streamlit run app.py
"""

import streamlit as st
import tensorflow as tf
from tensorflow import keras
from keras import layers
import pickle
import os

# ============================================================================
# CONFIGURACIÃ“N DE LA PÃGINA
# ============================================================================

st.set_page_config(
    page_title="ğŸ¬ Generador de ReseÃ±as",
    page_icon="ğŸ¬",
    layout="centered"  # UNA COLUMNA centrada
)

# ============================================================================
# CAPA PERSONALIZADA (DEBE ESTAR DEFINIDA PARA CARGAR MODELOS)
# ============================================================================

class PositionalEmbedding(layers.Layer):
    """Capa personalizada para embeddings posicionales"""
    
    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):
        super().__init__(**kwargs)
        self.sequence_length = sequence_length
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        
        self.token_embeddings = layers.Embedding(vocab_size, embed_dim)
        self.position_embeddings = layers.Embedding(sequence_length, embed_dim)
    
    def call(self, inputs):
        length = tf.shape(inputs)[-1]
        positions = tf.range(start=0, limit=length, delta=1)
        
        token_emb = self.token_embeddings(inputs)
        pos_emb = self.position_embeddings(positions)
        
        return token_emb + pos_emb
    
    def get_config(self):
        config = super().get_config()
        config.update({
            "sequence_length": self.sequence_length,
            "vocab_size": self.vocab_size,
            "embed_dim": self.embed_dim,
        })
        return config
    
    @classmethod
    def from_config(cls, config):
        return cls(**config)

# Registrar la capa personalizada para que pueda ser cargada
keras.utils.get_custom_objects()['PositionalEmbedding'] = PositionalEmbedding

# ============================================================================
# FUNCIONES PARA MÃ‰TRICAS
# ============================================================================

def get_model_info(model_name):
    """
    Obtiene informaciÃ³n tÃ©cnica de un modelo especÃ­fico.
    
    Args:
        model_name: "1" o "2"
    """
    model_file = f"saved_models/movie_model_{model_name}.keras"
    
    if not os.path.exists(model_file):
        return None
    
    try:
        model = keras.models.load_model(model_file)
        
        # InformaciÃ³n bÃ¡sica
        total_params = model.count_params()
        trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
        
        # Arquitectura
        layers_info = []
        for i, layer in enumerate(model.layers):
            layer_info = {
                'name': layer.name,
                'type': layer.__class__.__name__,
                'output_shape': str(layer.output_shape) if hasattr(layer, 'output_shape') else 'N/A',
                'params': layer.count_params()
            }
            layers_info.append(layer_info)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'layers': layers_info,
            'model': model
        }
        
    except Exception as e:
        st.error(f"Error cargando modelo {model_name}: {str(e)}")
        return None

def show_model_metrics(model_name):
    """Mostrar mÃ©tricas detalladas de un modelo especÃ­fico"""
    model_info = get_model_info(model_name)
    
    if not model_info:
        st.error(f"âŒ Modelo {model_name} no encontrado o no se pudo cargar")
        return
    
    # ConfiguraciÃ³n segÃºn el modelo
    config_info = {
        "1": {
            "nombre": "Transformer Simple",
            "capas_atencion": 1,
            "epocas_entrenamiento": 15,
            "learning_rate": 0.001,
            "fortalezas": ["MÃ¡s estable", "Menos overfitting", "Entrenamiento rÃ¡pido"],
            "uso_recomendado": "Texto coherente y predecible"
        },
        "2": {
            "nombre": "Transformer Doble",
            "capas_atencion": 2,
            "epocas_entrenamiento": 10,
            "learning_rate": 0.0005,
            "fortalezas": ["MÃ¡s expresivo", "Mayor capacidad", "Texto mÃ¡s creativo"],
            "uso_recomendado": "Contenido original y variado"
        }
    }
    
    config = config_info[model_name]
    
    st.success(f"ğŸ“Š **MÃ©tricas del Modelo {model_name}** - {config['nombre']}")
    
    # MÃ©tricas principales en una columna
    st.metric(
        label="ğŸ”¢ ParÃ¡metros Totales",
        value=f"{model_info['total_params']:,}",
        help="NÃºmero total de parÃ¡metros entrenables del modelo"
    )
    
    st.metric(
        label="ğŸ¯ Capas de AtenciÃ³n",
        value=config['capas_atencion'],
        help="NÃºmero de capas Transformer de atenciÃ³n mÃºltiple"
    )
    
    st.metric(
        label="ğŸ“š Ã‰pocas Entrenamiento",
        value=config['epocas_entrenamiento'],
        help="NÃºmero de Ã©pocas usadas durante el entrenamiento"
    )
    
    # InformaciÃ³n tÃ©cnica
    st.markdown("### ğŸ”§ ConfiguraciÃ³n TÃ©cnica")
    
    st.markdown(f"""
    **âš™ï¸ HiperparÃ¡metros:**
    - Learning Rate: `{config['learning_rate']}`
    - Vocabulario: `5,000 tokens`
    - Secuencia mÃ¡xima: `60 tokens`
    - Embedding dimension: `128`
    - Attention heads: `4`
    
    **ğŸ¯ CaracterÃ­sticas:**
    - ParÃ¡metros entrenables: `{model_info['trainable_params']:,}`
    - Arquitectura: `{config['nombre']}`
    - Dataset: `IMDb reviews`
    - TamaÃ±o muestra: `2,000 reseÃ±as`
    """)
    
    # Fortalezas del modelo
    st.markdown("### âœ¨ Fortalezas del Modelo")
    strengths_text = " â€¢ ".join(config['fortalezas'])
    st.info(f"**{config['uso_recomendado']}**\n\nâ€¢ {strengths_text}")
    
    # Arquitectura detallada
    with st.expander("ğŸ—ï¸ Ver Arquitectura Detallada"):
        st.markdown("#### Capas del Modelo:")
        
        for i, layer in enumerate(model_info['layers']):
            if layer['params'] > 0:  # Solo mostrar capas con parÃ¡metros
                st.markdown(f"""
                **Capa {i+1}: {layer['name']}**
                - Tipo: `{layer['type']}`
                - Forma salida: `{layer['output_shape']}`
                - ParÃ¡metros: `{layer['params']:,}`
                """)
    
    # Consejos de uso
    st.markdown("### ğŸ’¡ Consejos de Uso")
    
    if model_name == "1":
        st.markdown("""
        **ğŸ¯ Mejor para:**
        - Usuarios principiantes
        - ReseÃ±as coherentes y estables
        - Cuando necesitas resultados predecibles
        
        **ğŸŒ¡ï¸ Temperatura recomendada:** 0.5 - 0.8
        **ğŸ“ Longitud ideal:** 30-50 palabras
        """)
    else:
        st.markdown("""
        **ğŸ¯ Mejor para:**
        - Usuarios avanzados
        - Contenido mÃ¡s creativo y original
        - Cuando quieres variedad en el texto
        
        **ğŸŒ¡ï¸ Temperatura recomendada:** 0.7 - 1.2
        **ğŸ“ Longitud ideal:** 40-80 palabras
        """)

def compare_models():
    """Comparar ambos modelos lado a lado"""
    model1_info = get_model_info("1")
    model2_info = get_model_info("2")
    
    if not model1_info and not model2_info:
        st.error("âŒ No se encontraron modelos entrenados")
        return
    elif not model1_info:
        st.warning("âš ï¸ Solo el Modelo 2 estÃ¡ disponible")
        show_model_metrics("2")
        return
    elif not model2_info:
        st.warning("âš ï¸ Solo el Modelo 1 estÃ¡ disponible")
        show_model_metrics("1")
        return
    
    st.success("âš–ï¸ **ComparaciÃ³n de Modelos**")
    
    # ComparaciÃ³n en una columna
    st.markdown("### ğŸ¤– Modelo 1 - Simple")
    st.markdown(f"""
    **ğŸ“Š MÃ©tricas:**
    - ParÃ¡metros: `{model1_info['total_params']:,}`
    - Capas atenciÃ³n: `1`
    - Ã‰pocas: `15`
    - Learning Rate: `0.001`
    
    **âœ¨ Fortalezas:**
    - âœ… MÃ¡s estable
    - âœ… Menos overfitting  
    - âœ… Entrenamiento rÃ¡pido
    - âœ… Resultados predecibles
    
    **ğŸ¯ Mejor para:**
    - Principiantes
    - Texto coherente
    - Uso general
    """)
    
    st.divider()
    
    st.markdown("### ğŸ¤– Modelo 2 - Doble")
    st.markdown(f"""
    **ğŸ“Š MÃ©tricas:**
    - ParÃ¡metros: `{model2_info['total_params']:,}`
    - Capas atenciÃ³n: `2`
    - Ã‰pocas: `10`
    - Learning Rate: `0.0005`
    
    **âœ¨ Fortalezas:**
    - âœ… MÃ¡s expresivo
    - âœ… Mayor capacidad
    - âœ… Texto mÃ¡s creativo
    - âœ… Mejor para contenido original
    
    **ğŸ¯ Mejor para:**
    - Usuarios avanzados
    - Contenido creativo
    - Variedad en el texto
    """)
    
    # Recomendaciones
    st.markdown("### ğŸ¯ Recomendaciones de Uso")
    
    param_diff = model2_info['total_params'] - model1_info['total_params']
    param_percent = (param_diff / model1_info['total_params']) * 100
    
    st.info(f"""
    **ğŸ“ˆ Diferencias clave:**
    - El Modelo 2 tiene **{param_diff:,} parÃ¡metros mÃ¡s** ({param_percent:.1f}% mÃ¡s complejo)
    - El Modelo 1 es **mÃ¡s estable** para principiantes
    - El Modelo 2 es **mÃ¡s creativo** pero requiere ajuste fino
    
    **ğŸ’¡ Consejo:** Empieza con el Modelo 1, luego experimenta con el Modelo 2
    """)
    
    # Tabla de configuraciones recomendadas
    st.markdown("### âš™ï¸ Configuraciones Recomendadas")
    
    st.markdown("""
    | ParÃ¡metro | Modelo 1 | Modelo 2 |
    |-----------|----------|----------|
    | **Temperatura** | 0.5 - 0.8 | 0.7 - 1.2 |
    | **Longitud** | 30-50 palabras | 40-80 palabras |
    | **Uso ideal** | Texto coherente | Texto creativo |
    """)

# ============================================================================
# FUNCIONES PARA CARGAR MODELOS
# ============================================================================

@st.cache_resource
def load_model(model_name):
    """
    Carga un modelo especÃ­fico (1 o 2).
    
    Args:
        model_name: "1" o "2"
    """
    model_file = f"saved_models/movie_model_{model_name}.keras"
    
    if not os.path.exists(model_file):
        return None, f"No se encontrÃ³ {model_file}. Entrena el modelo primero."
    
    try:
        model = keras.models.load_model(model_file)
        return model, None
    except Exception as e:
        return None, f"Error cargando {model_file}: {str(e)}"

@st.cache_resource
def load_vectorizer():
    """Carga el traductor de palabras"""
    vectorizer_file = "saved_models/text_vectorizer.pkl"
    
    if not os.path.exists(vectorizer_file):
        return None, None, f"No se encontrÃ³ {vectorizer_file}. Entrena un modelo primero."
    
    try:
        with open(vectorizer_file, "rb") as f:
            vectorizer_data = pickle.load(f)
        
        # Recrear vectorizador de forma mÃ¡s simple
        vectorizer = keras.layers.TextVectorization(
            max_tokens=vectorizer_data['config']['max_tokens'],
            output_mode=vectorizer_data['config']['output_mode'],
            output_sequence_length=vectorizer_data['config']['output_sequence_length']
        )
        
        # Inicializar con datos dummy de forma mÃ¡s compatible
        dummy_texts = ["dummy text", "another text", "more text"]
        dummy_dataset = tf.data.Dataset.from_tensor_slices(dummy_texts).batch(1)
        vectorizer.adapt(dummy_dataset)
        
        # Cargar los pesos reales
        vectorizer.set_weights(vectorizer_data['weights'])
        
        # Crear diccionario de palabras
        vocabulary = vectorizer_data['vocabulary']
        id_to_word = {i: word for i, word in enumerate(vocabulary)}
        
        return vectorizer, id_to_word, None
        
    except Exception as e:
        return None, None, f"Error cargando vectorizer: {str(e)}"

# ============================================================================
# FUNCIÃ“N DE GENERACIÃ“N
# ============================================================================

def generate_review(model, vectorizer, id_to_word, prompt, temperature, max_words):
    """Genera una reseÃ±a con el modelo seleccionado"""
    try:
        current_text = prompt
        words_generated = 0
        
        # Mostrar progreso
        progress_placeholder = st.empty()
        
        for i in range(max_words):
            # Actualizar progreso
            progress_placeholder.text(f"ğŸ¤– Generando palabra {i+1}/{max_words}...")
            
            # Vectorizar texto actual
            input_ids = vectorizer([current_text])
            
            # Predecir siguiente palabra
            predictions = model(input_ids)
            last_word_probs = predictions[0, -1, :]
            
            # Aplicar temperatura para controlar creatividad
            last_word_probs = last_word_probs / temperature
            last_word_probs = tf.nn.softmax(last_word_probs)
            
            # Elegir siguiente palabra
            next_word_id = tf.random.categorical([last_word_probs], 1)[0, 0].numpy()
            
            # Convertir ID a palabra
            if next_word_id in id_to_word:
                next_word = id_to_word[next_word_id]
                
                # Filtrar palabras problemÃ¡ticas
                if next_word in ['[UNK]', '', ' ', '<pad>', '<start>', '<end>']:
                    continue
                
                # AÃ±adir nueva palabra
                current_text += " " + next_word
                words_generated += 1
                
                # Parar en punto final si ya tenemos suficiente texto
                if next_word.endswith('.') and words_generated > 10:
                    break
        
        # Limpiar progreso
        progress_placeholder.empty()
        
        return current_text, words_generated
        
    except Exception as e:
        return f"Error generando: {str(e)}", 0

# ============================================================================
# INTERFAZ PRINCIPAL
# ============================================================================

def main():
    """Interfaz principal de una columna"""
    
    # TÃTULO
    st.title("ğŸ¬ Generador de ReseÃ±as de PelÃ­culas")
    st.markdown("*Genera reseÃ±as automÃ¡ticamente con Inteligencia Artificial*")
    
    # SELECCIÃ“N DE MODELO
    st.subheader("ğŸ¤– Selecciona el Modelo")
    
    model_choice = st.radio(
        "Â¿QuÃ© modelo usar?",
        ["1", "2"],
        format_func=lambda x: f"Modelo {x} ({'Simple' if x == '1' else 'Doble'})",
        horizontal=True
    )
    
    st.info(f"""
    **Modelo {model_choice}:**
    {"â€¢ Una capa Transformer" if model_choice == "1" else "â€¢ Dos capas Transformer"}
    {"â€¢ MÃ¡s estable y rÃ¡pido" if model_choice == "1" else "â€¢ MÃ¡s creativo y complejo"}
    {"â€¢ Recomendado para empezar" if model_choice == "1" else "â€¢ Para usuarios avanzados"}
    """)
    
    # CARGAR MODELO Y VECTORIZADOR
    model, model_error = load_model(model_choice)
    vectorizer, id_to_word, vec_error = load_vectorizer()
    
    # VERIFICAR ERRORES
    if model_error or vec_error:
        st.error(f"âŒ {model_error or vec_error}")
        st.warning("ğŸ’¡ **SoluciÃ³n:** Ejecuta primero el entrenamiento:")
        st.code(f"python train.py --modelo {model_choice}")
        st.stop()
    
    st.success(f"âœ… Modelo {model_choice} cargado correctamente")
    
    # SEPARADOR
    st.divider()
    
    # CONFIGURACIÃ“N DE GENERACIÃ“N
    st.subheader("âœï¸ Escribe tu ReseÃ±a")
    
    # Prompt del usuario
    prompt = st.text_area(
        "Â¿CÃ³mo quieres que empiece la reseÃ±a?",
        value="This movie is",
        height=100,
        help="Escribe las primeras palabras y la IA completarÃ¡ el resto",
        placeholder="Ejemplo: 'This movie is'"
    )
    
    # Controles
    temperature = st.slider(
        "ğŸŒ¡ï¸ Creatividad",
        min_value=0.1,
        max_value=2.0,
        value=0.7,
        step=0.1,
        help="0.1 = muy conservador y predecible\n2.0 = muy creativo y arriesgado"
    )
    
    max_words = st.slider(
        "ğŸ“ Longitud",
        min_value=10,
        max_value=100,
        value=50,
        step=5,
        help="NÃºmero mÃ¡ximo de palabras a generar"
    )
    
    # BOTÃ“N DE GENERACIÃ“N
    if st.button("ğŸš€ Generar ReseÃ±a", type="primary", use_container_width=True):
        if not prompt.strip():
            st.error("âŒ Por favor escribe algo para empezar la reseÃ±a")
        else:
            # Generar reseÃ±a
            with st.spinner("ğŸ¤– La IA estÃ¡ escribiendo tu reseÃ±a..."):
                generated_text, words_added = generate_review(
                    model, vectorizer, id_to_word, 
                    prompt, temperature, max_words
                )
            
            # Mostrar resultado
            if words_added > 0:
                st.success("ğŸ‰ Â¡ReseÃ±a generada exitosamente!")
                
                # Mostrar la reseÃ±a con estilo
                st.markdown("### ğŸ“ Tu ReseÃ±a:")
                st.markdown(f"""
                <div style="
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    padding: 25px;
                    border-radius: 15px;
                    color: white;
                    font-size: 18px;
                    line-height: 1.8;
                    box-shadow: 0 8px 25px rgba(0,0,0,0.15);
                    margin: 20px 0;
                    border: 2px solid rgba(255,255,255,0.1);
                ">
                    <strong>"{generated_text}"</strong>
                </div>
                """, unsafe_allow_html=True)
                
                # EstadÃ­sticas
                total_words = len(generated_text.split())
                st.markdown(f"""
                **ğŸ“Š EstadÃ­sticas:**
                - ğŸ”¤ Palabras aÃ±adidas: {words_added}
                - ğŸ“ Total de palabras: {total_words}
                - ğŸŒ¡ï¸ Creatividad usada: {temperature}
                - ğŸ¤– Modelo: {model_choice} ({'Simple' if model_choice == '1' else 'Doble'})
                """)
                
                # BotÃ³n para generar otra
                if st.button("ğŸ”„ Generar otra versiÃ³n", use_container_width=True):
                    st.rerun()
            else:
                st.error("âŒ No se pudo generar la reseÃ±a. Intenta ajustar los parÃ¡metros.")
    
    # SEPARADOR
    st.divider()
    
    # MÃ‰TRICAS DE LOS MODELOS
    st.subheader("ğŸ“Š MÃ©tricas de los Modelos")
    
    if st.button("ğŸ“ˆ Ver MÃ©tricas Modelo 1", use_container_width=True):
        show_model_metrics("1")
    
    if st.button("ğŸ“ˆ Ver MÃ©tricas Modelo 2", use_container_width=True):
        show_model_metrics("2")
    
    # BotÃ³n para comparar ambos modelos
    if st.button("âš–ï¸ Comparar Ambos Modelos", type="secondary", use_container_width=True):
        compare_models()
    
    # INFORMACIÃ“N DEL PROYECTO
    with st.expander("â„¹ï¸ Â¿CÃ³mo funciona este proyecto?"):
        st.markdown(f"""
        ### ğŸ§  TecnologÃ­a
        
        **Modelo Transformer {model_choice}:**
        - {"ğŸ”¹ Una capa de atenciÃ³n (mÃ¡s simple)" if model_choice == "1" else "ğŸ”¹ Dos capas de atenciÃ³n (mÃ¡s complejo)"}
        - ğŸ”¹ Entrenado con reseÃ±as reales de IMDb
        - ğŸ”¹ Vocabulario de 5,000 palabras cinematogrÃ¡ficas
        
        ### ğŸ¯ Â¿CÃ³mo genera texto?
        1. **Lee** el inicio que escribes
        2. **Analiza** patrones de las reseÃ±as que conoce
        3. **Predice** quÃ© palabra podrÃ­a venir despuÃ©s
        4. **Repite** el proceso hasta formar una reseÃ±a completa
        
        ### ğŸ› ï¸ TecnologÃ­as usadas
        - **TensorFlow**: Framework de IA
        - **Transformers**: Arquitectura del modelo
        - **Dataset IMDb**: ReseÃ±as reales para entrenamiento
        - **Streamlit**: Esta interfaz web
        
        ### ğŸ›ï¸ Controles
        - **Creatividad baja (0.1-0.5)**: Texto mÃ¡s predecible y coherente
        - **Creatividad media (0.6-1.0)**: Balance entre coherencia y originalidad
        - **Creatividad alta (1.1-2.0)**: Texto mÃ¡s arriesgado y creativo
        """)

if __name__ == "__main__":
    main()